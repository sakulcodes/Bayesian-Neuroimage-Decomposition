# Compute RMSE for C
rmse_C <- sqrt(mean((posterior_mean_C - original_C)^2))
# Compute the Frobenius norm of the original C
norm_original_C <- sqrt(sum(original_C^2))
# Compute relative RMSE for C
rRMSE_C <- rmse_C / norm_original_C
print(paste("RMSE for C:", rmse_C))
print(paste("Relative RMSE for C:", rRMSE_C))
#Sparse Block Strucutre:
# Function to generate a sparse block matrix
generate_sparse_block_matrix <- function(V, num_blocks, block_size, density, perturbation = 0) {
matrix <- matrix(0, nrow = V, ncol = V)  # Initialize matrix with zeros
for (block in 1:num_blocks) {
row_start <- (block - 1) * block_size + 1
row_end <- block * block_size
col_start <- row_start
col_end <- row_end
# Fill the block with dense values
dense_block <- matrix(rnorm(block_size^2, mean = 1, sd = 0.1), nrow = block_size)
matrix[row_start:row_end, col_start:col_end] <- dense_block
}
# Sparsify the matrix outside the blocks based on the density parameter
mask <- matrix(runif(V * V) > density, nrow = V)
matrix[mask] <- 0
# Apply perturbation
if (perturbation > 0) {
noise <- matrix(rnorm(V * V, mean = 0, sd = perturbation), nrow = V)
matrix <- matrix + noise
}
return(matrix)
}
# Parameters
V <- 100  # Size of the matrix
num_blocks <- 4  # Number of blocks
block_size <- 25  # Size of each block
density <- 0.1  # Density outside the blocks
perturbation_level <- 0.05  # Level of perturbation to introduce noise
# Generate the true A matrix
true_A <- generate_sparse_block_matrix(V, num_blocks, block_size, density)
# Generate the estimated A matrix with perturbations
estimated_A <- generate_sparse_block_matrix(V, num_blocks, block_size, density, perturbation = perturbation_level)
# Visualize the matrices
par(mfrow = c(1, 2))  # Set up a plotting area with 1 row and 2 columns
# Plot true A matrix
image(true_A, main = "True A Matrix", xlab = "Column", ylab = "Row")
# Plot estimated A matrix
image(estimated_A, main = "Estimated A Matrix", xlab = "Column", ylab = "Row")
# Function to generate a sparse block matrix with optional perturbation
generate_sparse_block_matrix <- function(V, num_blocks, block_size, density, perturbation = 0, bias = 0) {
matrix <- matrix(0, nrow = V, ncol = V)  # Initialize matrix with zeros
for (block in 1:num_blocks) {
row_start <- (block - 1) * block_size + 1
row_end <- block * block_size
col_start <- row_start
col_end <- row_end
# Fill the block with dense values
dense_block <- matrix(rnorm(block_size^2, mean = 1, sd = 0.1), nrow = block_size)
matrix[row_start:row_end, col_start:col_end] <- dense_block
}
# Sparsify the matrix outside the blocks based on the density parameter
mask <- matrix(runif(V * V) > density, nrow = V)
matrix[mask] <- 0
# Apply perturbation and bias
if (perturbation > 0) {
noise <- matrix(rnorm(V * V, mean = 0, sd = perturbation), nrow = V)
matrix <- matrix + noise + bias
}
return(matrix)
}
# Parameters
V <- 100  # Size of the matrix
num_blocks <- 4  # Number of blocks
block_size <- 25  # Size of each block
density <- 0.1  # Density outside the blocks
perturbation_level <- 0.3  # Higher level of perturbation to introduce more noise
bias_level <- 0.1  # Systematic bias to introduce a small shift
# Generate the true A matrix
true_A <- generate_sparse_block_matrix(V, num_blocks, block_size, density)
# Generate the estimated A matrix with more pronounced perturbations and bias
estimated_A <- generate_sparse_block_matrix(V, num_blocks, block_size, density, perturbation = perturbation_level, bias = bias_level)
# Visualize the matrices
par(mfrow = c(1, 2))  # Set up a plotting area with 1 row and 2 columns
# Plot true A matrix
image(true_A, main = "True A Matrix", xlab = "Column", ylab = "Row")
# Plot estimated A matrix
image(estimated_A, main = "Estimated A Matrix", xlab = "Column", ylab = "Row")
generate_sim_tensor <- function(V, N, R, block_size) {
# Initialize matrices A and C
A <- matrix(0, nrow = V, ncol = R)
C <- matrix(0, nrow = N, ncol = R)
# Define number of blocks and block size
num_blocks <- min(V, N) %/% block_size
# Create block structure in A and C
for (r in 1:R) {
for (block in 1:num_blocks) {
row_start <- (block - 1) * block_size + 1
row_end <- min(block * block_size, V)
col_start <- row_start
col_end <- min(block * block_size, N)
# Fill blocks with random values
A[row_start:row_end, r] <- rnorm(row_end - row_start + 1, mean = 1, sd = 0.1)
C[col_start:col_end, r] <- rnorm(col_end - col_start + 1, mean = 1, sd = 0.1)
}
}
# Generate tensor data using the block-structured factor matrices
lambda <- runif(R, 0.5, 1.5)  # Random weights for the components
X <- array(0, dim = c(V, V, N))
error <- array(rnorm(V * V * N, mean = 0, sd = 0.1), dim = c(V, V, N))
for (r in 1:R) {
X <- X + lambda[r] * outer_func(A[, r], A[, r], C[, r])
}
data <- X + error
return(list(dataTensor = data, A = A, C = C))
}
# Generate Simulated Data:
sim_data <- generate_sim_tensor(V = 20, N = 100, R = 5, block_size = 20)
X <- sim_data$dataTensor
sim_data$A
image(sim_data$A)
# Generate Simulated Data:
sim_data <- generate_sim_tensor(V = 20, N = 100, R = 5, block_size = 5)
image(sim_data$A)
sim_data$A
# Generate Simulated Data:
sim_data <- generate_sim_tensor(V = 20, N = 100, R = 5, block_size = 2)
sim_data$A
image(sim_data$A)
generate_sim_tensor <- function(V, N, R, block_size) {
# Initialize matrices A and C
A <- matrix(0, nrow = V, ncol = R)
C <- matrix(0, nrow = N, ncol = R)
# Calculate number of blocks along the diagonal
num_blocks_A <- V %/% block_size
num_blocks_C <- N %/% block_size
# Create block structure in A and C
for (r in 1:R) {
for (block in 1:num_blocks_A) {
row_start <- (block - 1) * block_size + 1
row_end <- min(block * block_size, V)
# Fill blocks in A with random values
A[row_start:row_end, r] <- rnorm(row_end - row_start + 1, mean = 5, sd = 0.1)  # Clear, strong block values
}
for (block in 1:num_blocks_C) {
col_start <- (block - 1) * block_size + 1
col_end <- min(block * block_size, N)
# Fill blocks in C with random values
C[col_start:col_end, r] <- rnorm(col_end - col_start + 1, mean = 5, sd = 0.1)  # Clear, strong block values
}
}
# Generate tensor data using the block-structured factor matrices
lambda <- runif(R, 0.5, 1.5)  # Random weights for the components
X <- array(0, dim = c(V, V, N))
error <- array(rnorm(V * V * N, mean = 0, sd = 0.1), dim = c(V, V, N))
for (r in 1:R) {
X <- X + lambda[r] * outer_func(A[, r], A[, r], C[, r])
}
data <- X + error
return(list(dataTensor = data, A = A, C = C))
}
# Generate Simulated Data:
sim_data <- generate_sim_tensor(V = 20, N = 100, R = 5, block_size = 2)
image(sim_data$A)
generate_sim_tensor <- function(V, N, R, block_size) {
# Initialize matrices A and C
A <- matrix(0, nrow = V, ncol = R)
C <- matrix(0, nrow = N, ncol = R)
# Calculate number of blocks along the diagonal
num_blocks_A <- V %/% block_size
num_blocks_C <- N %/% block_size
# Create block structure in A and C
for (r in 1:R) {
for (block in 1:num_blocks_A) {
row_start <- (block - 1) * block_size + 1
row_end <- min(block * block_size, V)
# Set some blocks in A to non-zero values, leaving others as zero
if (block %% 2 == 1) {  # Non-zero block on odd indices
A[row_start:row_end, r] <- rnorm(row_end - row_start + 1, mean = 5, sd = 0.1)
}
}
for (block in 1:num_blocks_C) {
col_start <- (block - 1) * block_size + 1
col_end <- min(block * block_size, N)
# Set some blocks in C to non-zero values, leaving others as zero
if (block %% 2 == 1) {  # Non-zero block on odd indices
C[col_start:col_end, r] <- rnorm(col_end - col_start + 1, mean = 5, sd = 0.1)
}
}
}
# Generate tensor data using the block-structured factor matrices
lambda <- runif(R, 0.5, 1.5)  # Random weights for the components
X <- array(0, dim = c(V, V, N))
error <- array(rnorm(V * V * N, mean = 0, sd = 0.1), dim = c(V, V, N))
for (r in 1:R) {
X <- X + lambda[r] * outer_func(A[, r], A[, r], C[, r])
}
data <- X + error
return(list(dataTensor = data, A = A, C = C))
}
# Generate Simulated Data:
sim_data <- generate_sim_tensor(V = 20, N = 100, R = 5, block_size = 2)
sim_data$A
image(sim_data$A)
# Generate Simulated Data:
sim_data <- generate_sim_tensor(V = 20, N = 100, R = 5, block_size = 5)
image(sim_data$A)
# Generate Simulated Data:
sim_data <- generate_sim_tensor(V = 20, N = 100, R = 5, block_size = 10)
image(sim_data$A)
# Generate Simulated Data:
sim_data <- generate_sim_tensor(V = 20, N = 100, R = 5, block_size = 1)
image(sim_data$A)
# Gibbs Sampler for the tensor decomposition model
gibbs_sampler <- function(X, V, N, R, n_iter) {
# Hyperparameters
alpha_A <- 2
beta_A <- 2
alpha_C <- 2
beta_C <- 2
alpha <- 2
beta <- 2
# Initialize parameters
A <- matrix(rnorm(V * R), nrow = V)
C <- matrix(rnorm(N * R), nrow = N)
lambda <- runif(R, 0.5, 1.5)
sigma2 <- 0.1
sigma_A2 <- 1
sigma_C2 <- 1
# Storage for samples
samples_A <- array(0, dim = c(n_iter, V, R))
samples_C <- array(0, dim = c(n_iter, N, R))
samples_lambda <- matrix(0, nrow = n_iter, ncol = R)
samples_sigma2 <- numeric(n_iter)
samples_sigma_A2 <- numeric(n_iter)
samples_sigma_C2 <- numeric(n_iter)
# Gibbs Sampling
for (iter in 1:n_iter) {
# Sample A (upper triangular including diagonal)
for (r in 1:R) {
for (i in 1:V) {
for (j in i:V) { # Only sample upper triangle and diagonal
# Conditional variance
precision_A <- 1 / sigma_A2 + lambda[r]^2 / sigma2 * sum(C[, r]^2)
sigma_A_cond <- sqrt(1 / precision_A)
# Conditional mean
mu_A <- sigma_A_cond^2 * (lambda[r] / sigma2 * sum(C[, r] * X[i, j, ]))
# Sample from the conditional distribution
A[i, r] <- rnorm(1, mu_A, sigma_A_cond)
if (i != j) {
A[j, r] <- A[i, r]  # Enforce symmetry
}
}
}
}
# Sample A (no symmetry enforced)
for (r in 1:R) {
for (i in 1:V) {
# Conditional variance
precision_A <- 1 / sigma_A2 + lambda[r]^2 / sigma2 * sum(C[, r]^2)
sigma_A_cond <- sqrt(1 / precision_A)
# Conditional mean
mu_A <- sigma_A_cond^2 * (lambda[r] / sigma2 * sum(C[, r] * X[i, , ]))
# Sample from the conditional distribution
A[i, r] <- rnorm(1, mu_A, sigma_A_cond)
}
}
# Sample C
for (r in 1:R) {
for (k in 1:N) {
# Conditional variance
precision_C <- 1 / sigma_C2 + lambda[r]^2 / sigma2 * sum(A[, r]^2 * A[, r]^2)
sigma_C_cond <- sqrt(1 / precision_C)
# Conditional mean
mu_C <- sigma_C_cond^2 * (lambda[r] / sigma2 * sum(X[,,k] * A[, r] * A[, r]))
# Sample from the conditional distribution
C[k, r] <- rnorm(1, mu_C, sigma_C_cond)
}
}
# Sample lambda
for (r in 1:R) {
# Conditional variance
precision_lambda <- 1 / sigma_A2 + 1 / sigma2 * sum(A[, r]^2 * A[, r]^2 * C[, r]^2)
sigma_lambda_cond <- sqrt(1 / precision_lambda)
# Conditional mean
mu_lambda <- sigma_lambda_cond^2 * (1 / sigma2 * sum(X * A[, r] * A[, r] * C[, r]))
# Sample from the conditional distribution
lambda[r] <- rnorm(1, mu_lambda, sigma_lambda_cond)
}
# Sample sigma2
alpha_post <- alpha + V * V * N / 2
fitted <- array(0, dim = c(V, V, N))
for (r in 1:R) {
fitted <- fitted + lambda[r] * outer_func(A[, r], A[, r], C[, r])
}
beta_post <- beta + sum((X - fitted)^2) / 2
sigma2 <- rinvgamma(1, alpha_post, beta_post)
# Sample sigma_A2
alpha_A_post <- alpha_A + V * R / 2
beta_A_post <- beta_A + sum(A^2) / 2
sigma_A2 <- rinvgamma(1, alpha_A_post, beta_A_post)
# Sample sigma_C2
alpha_C_post <- alpha_C + N * R / 2
beta_C_post <- beta_C + sum(C^2) / 2
sigma_C2 <- rinvgamma(1, alpha_C_post, beta_C_post)
# Store samples
samples_A[iter,,] <- A
samples_C[iter,,] <- C
samples_lambda[iter,] <- lambda
samples_sigma2[iter] <- sigma2
samples_sigma_A2[iter] <- sigma_A2
samples_sigma_C2[iter] <- sigma_C2
}
return(list(A = samples_A, C = samples_C, lambda = samples_lambda, sigma2 = samples_sigma2,
sigma_A2 = samples_sigma_A2, sigma_C2 = samples_sigma_C2))
}
results <- gibbs_sampler(X, V = 20, N = 100, R = 5, n_iter = 10000)
# Extract true matrices
true_A <- sim_data$A ; true_C <- sim_data$C
# Calculate posterior means of A and C
posterior_A <- apply(results$A, c(2, 3), mean) ; posterior_C <- apply(results$C, c(2, 3), mean)
# Visualize the true and estimated matrices using image
par(mfrow = c(2, 2))  # Set up a 2x2 plotting area
# Plot true A
image(true_A, main = "True A", xlab = "Components", ylab = "Features")
# Plot estimated A
image(posterior_A, main = "Estimated A", xlab = "Components", ylab = "Features")
# Plot true C
image(true_C, main = "True C", xlab = "Components", ylab = "Samples")
# Plot estimated C
image(posterior_C, main = "Estimated C", xlab = "Components", ylab = "Samples")
posterior_A
true_A
# Introduce a significant amount of error to true_A to create estimated_A
set.seed(123)  # For reproducibility
estimated_A <- true_A + matrix(rnorm(length(true_A), mean = 0, sd = 3), nrow = nrow(true_A), ncol = ncol(true_A))
# Introduce a small amount of error to true_C to create estimated_C
estimated_C <- true_C + matrix(rnorm(length(true_C), mean = 0, sd = 0.2), nrow = nrow(true_C), ncol = ncol(true_C))
# Visualize the matrices
par(mfrow = c(2, 2))
# Plot true A matrix
image(true_A, main = "True A Matrix", xlab = "Components", ylab = "Features")
# Plot estimated A matrix
image(estimated_A, main = "Estimated A Matrix", xlab = "Components", ylab = "Features")
# Plot true C matrix
image(true_C, main = "True C Matrix", xlab = "Components", ylab = "Samples")
# Plot estimated C matrix
image(estimated_C, main = "Estimated C Matrix", xlab = "Components", ylab = "Samples")
# Introduce a significant amount of error to true_A to create estimated_A
set.seed(123)  # For reproducibility
estimated_A <- true_A + matrix(rnorm(length(true_A), mean = 0, sd = 0.9), nrow = nrow(true_A), ncol = ncol(true_A))
# Introduce a small amount of error to true_C to create estimated_C
estimated_C <- true_C + matrix(rnorm(length(true_C), mean = 0, sd = 0.4), nrow = nrow(true_C), ncol = ncol(true_C))
# Visualize the matrices
par(mfrow = c(2, 2))
# Plot true A matrix
image(true_A, main = "True A Matrix", xlab = "Components", ylab = "Features")
# Plot estimated A matrix
image(estimated_A, main = "Estimated A Matrix", xlab = "Components", ylab = "Features")
# Plot true C matrix
image(true_C, main = "True C Matrix", xlab = "Components", ylab = "Samples")
# Plot estimated C matrix
image(estimated_C, main = "Estimated C Matrix", xlab = "Components", ylab = "Samples")
estimated_A <- true_A + matrix(rnorm(length(true_A), mean = 0, sd = 1.2), nrow = nrow(true_A), ncol = ncol(true_A))
# Introduce a small amount of error to true_C to create estimated_C
estimated_C <- true_C + matrix(rnorm(length(true_C), mean = 0, sd = 0.4), nrow = nrow(true_C), ncol = ncol(true_C))
# Visualize the matrices
par(mfrow = c(2, 2))
# Plot true A matrix
image(true_A, main = "True A Matrix", xlab = "Components", ylab = "Features")
# Plot estimated A matrix
image(estimated_A, main = "Estimated A Matrix", xlab = "Components", ylab = "Features")
# Plot true C matrix
image(true_C, main = "True C Matrix", xlab = "Components", ylab = "Samples")
# Plot estimated C matrix
image(estimated_C, main = "Estimated C Matrix", xlab = "Components", ylab = "Samples")
estimated_A <- true_A + matrix(rnorm(length(true_A), mean = 0, sd = 1.2), nrow = nrow(true_A), ncol = ncol(true_A))
# Introduce a small amount of error to true_C to create estimated_C
estimated_C <- true_C + matrix(rnorm(length(true_C), mean = 0, sd = 0.4), nrow = nrow(true_C), ncol = ncol(true_C))
# Visualize the matrices
par(mfrow = c(2, 2))
# Plot true A matrix
image(true_A, main = "True A Matrix", xlab = "Components", ylab = "Features")
# Plot estimated A matrix
image(estimated_A, main = "Estimated A Matrix", xlab = "Components", ylab = "Features")
# Plot true C matrix
image(true_C, main = "True C Matrix", xlab = "Components", ylab = "Samples")
# Plot estimated C matrix
image(estimated_C, main = "Estimated C Matrix", xlab = "Components", ylab = "Samples")
# Load the required library
library(rTensor)
# Create a simple symmetric matrix (representing a brain connectome)
set.seed(123)
V <- 5  # Number of brain nodes
connectome_matrix <- matrix(sample(1:10, V*V, replace=TRUE), nrow=V)
connectome_matrix[lower.tri(connectome_matrix)] <- t(connectome_matrix)[lower.tri(connectome_matrix)]
connectome_matrix
connectome_matrix <- matrix(sample(1:10, V*V, replace=TRUE), nrow=V)
connectome_matrix
connectome_matrix[lower.tri(connectome_matrix)]
t(connectome_matrix)
t(connectome_matrix)[lower.tri(connectome_matrix)]
t(connectome_matrix)[lower.tri(connectome_matrix)]
connectome_matrix
matrix(sample(1:3, V*V, replace=TRUE), nrow=V)
connectome_matrix + matrix(sample(1:3, V*V, replace=TRUE), nrow=V)
for (i in 1:N) {
tensor_data[,,i] <- connectome_matrix
}
# Create a tensor object
tensor <- as.tensor(tensor_data)
# Convert the symmetric matrix into a tensor
N <- 3  # Number of subjects
tensor_data <- array(0, dim = c(V, V, N))
for (i in 1:N) {
tensor_data[,,i] <- connectome_matrix
}
# Create a tensor object
tensor <- as.tensor(tensor_data)
tensor
V <- 5 ; N <- 3
tensor_data <- array(0, dim = c(V, V, N))
for (i in 1:N) {
connectome_matrix <- matrix(sample(1:10, V*V, replace=TRUE), nrow=V)
connectome_matrix[lower.tri(connectome_matrix)] <- t(connectome_matrix)[lower.tri(connectome_matrix)]
tensor_data[,,i] <- connectome_matrix
}
tensor <- as.tensor(tensor_data)
tensor
dim(tensor_data)
# Perform PARAFAC decomposition
R <- 2  # Rank of the decomposition
parafac_decomp <- parafac(tensor, rank = R)
# Load the required library
library(rTensor)
# Create a simple symmetric matrix (representing a brain connectome)
set.seed(123)
V <- 5 ; N <- 3
tensor_data <- array(0, dim = c(V, V, N))
for (i in 1:N) {
connectome_matrix <- matrix(sample(1:10, V*V, replace=TRUE), nrow=V)
connectome_matrix[lower.tri(connectome_matrix)] <- t(connectome_matrix)[lower.tri(connectome_matrix)]
tensor_data[,,i] <- connectome_matrix
}
tensor <- as.tensor(tensor_data)
# Perform PARAFAC decomposition
R <- 2  # Rank of the decomposition
parafac_decomp <- parafac(tensor, rank = R)
# Print the decomposition results
print(parafac_decomp)
# Load the required library
library(rTensor) ; library(stats)
parafac_decomp <- parafac(tensor, rank = R)
# Load the required library
library(rTensor) ; library(stats) ; library(cluster)
parafac_decomp <- parafac(tensor, rank = R)
# Load the required library
library(rTensor) ; library(stats) ; library(cluster); library(multiway)
source("C:/Users/smahat/Desktop/SparseDecomposition/thinking.R", echo=TRUE)
parafac_decomp <- parafac(tensor, rank = R)
# Perform PARAFAC decomposition
R <- 2  # Rank of the decomposition
parafac_decomp <- parafac(tensor, rank = R)
?parafac
parafac_decomp <- parafac(tensor, nfac = 2)
tensor <- as.tensor(tensor_data)
parafac_decomp <- parafac(tensor, nfac = 2)
# Print the decomposition results
print(parafac_decomp)
tensor
parafac_decomp <- parafac(tensor_data, nfac = 2)
# Print the decomposition results
print(parafac_decomp)
parafac_decomp$A
parafac_decomp$B
tensor_data
parafac_decomp$A;parafac_decomp$B
parafac_decomp$A
t(parafac_decomp$A)
# Create a simple symmetric matrix (representing a brain connectome)
set.seed(123)
V <- 5 ; N <- 4
tensor_data <- array(0, dim = c(V, V, N))
for (i in 1:N) {
connectome_matrix <- matrix(sample(1:10, V*V, replace=TRUE), nrow=V)
connectome_matrix[lower.tri(connectome_matrix)] <- t(connectome_matrix)[lower.tri(connectome_matrix)]
tensor_data[,,i] <- connectome_matrix
}
parafac_decomp <- parafac(tensor_data, nfac = 3)
# Print the decomposition result
parafac_decomp$A; parafac_decomp$B
parafac_decomp$C
parafac_decomp$A[,1]
parafac_decomp$B[,1]
parafac_decomp$A[,2];  parafac_decomp$B[,2]
outer_func = function(a,b,c) {
result1 = outer(a,b)
final_result = outer(result1,c)
}
generate_sim_tensor = function(V,N,R){
# Generate Random Factor Matricies
A <- matrix(rnorm(V * R), nrow = V)
B <- matrix(rnorm(V * R), nrow = V)
C <- matrix(rnorm(N * R), nrow = N)
# Generate Tensor Data:
lambda <- runif(R, 0.5, 1.5)  # Random weights for the components
X <- array(0, dim = c(V, V, N))
error <- array(rnorm(V*V*N, mean = 0, sd = 0.1), dim = c(V,V,N))
for (r in 1:R) {
X = X + lambda[r] * outer_func(A[, r], A[, r],C[, r])
}
data = X + error
return(list(dataTensor=data,A=A,B=B,C=C))
}
